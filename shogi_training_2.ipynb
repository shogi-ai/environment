{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import gymnasium as gym\n",
    "\n",
    "from env import ShogiEnv\n",
    "from model.shogi_agent import ShogiAgent\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gym.register(id=\"Shogi-v0\", entry_point=\"env:ShogiEnv\")\n",
    "env: ShogiEnv = gym.make(\"Shogi-v0\")\n",
    "agent = ShogiAgent()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T19:00:36.960615500Z",
     "start_time": "2024-05-26T19:00:35.976177500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def play_game(player: ShogiAgent) -> (float, bool, bool):\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    env.reset()\n",
    "    agent.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    while not terminated and not truncated:\n",
    "        action_taken = player.select_action(env)\n",
    "        bit_state, reward, terminated, truncated, _ = env.step(action_taken)\n",
    "        player.adaptive_e_greedy()\n",
    "        total_reward += reward\n",
    "    return total_reward, terminated, truncated"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T19:00:37.641361200Z",
     "start_time": "2024-05-26T19:00:37.570357900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T19:00:43.946289600Z",
     "start_time": "2024-05-26T19:00:39.485546800Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n\u001B[0;32m      3\u001B[0m     start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 4\u001B[0m     _reward, _terminated, _truncated \u001B[38;5;241m=\u001B[39m \u001B[43mplay_game\u001B[49m\u001B[43m(\u001B[49m\u001B[43magent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mend\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[18], line 9\u001B[0m, in \u001B[0;36mplay_game\u001B[1;34m(player)\u001B[0m\n\u001B[0;32m      6\u001B[0m total_reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m terminated \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m truncated:\n\u001B[1;32m----> 9\u001B[0m     action_taken \u001B[38;5;241m=\u001B[39m \u001B[43mplayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect_action\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     bit_state, reward, terminated, truncated, _ \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action_taken)\n\u001B[0;32m     11\u001B[0m     player\u001B[38;5;241m.\u001B[39madaptive_e_greedy()\n",
      "File \u001B[1;32m~\\Desktop\\ict\\sem7\\data_challange\\environment\\model\\shogi_agent.py:105\u001B[0m, in \u001B[0;36mShogiAgent.select_action\u001B[1;34m(self, env)\u001B[0m\n\u001B[0;32m    101\u001B[0m     policy_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_network(\n\u001B[0;32m    102\u001B[0m         current_state_tensor, valid_moves_tensor\n\u001B[0;32m    103\u001B[0m     )\n\u001B[0;32m    104\u001B[0m     chosen_move_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(policy_values\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m--> 105\u001B[0m     chosen_move \u001B[38;5;241m=\u001B[39m \u001B[43mvalid_move_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mchosen_move_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    107\u001B[0m     chosen_move \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39msample_action()\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "progress = []\n",
    "for i in range(100):\n",
    "    start = time.time()\n",
    "    _reward, _terminated, _truncated = play_game(agent)\n",
    "    end = time.time()\n",
    "    print(f\"{i}: {end - start}\")\n",
    "\n",
    "    progress.append(\n",
    "        {\n",
    "            \"reward\": _reward,\n",
    "            \"terminated\": _terminated,\n",
    "            \"truncated\": _truncated,\n",
    "            \"duration\": end - start,\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
