{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'env'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menviourment\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ShogiEnv\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01magent\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mshogi_agent\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ShogiAgent\n\u001B[0;32m     10\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m gym\u001B[38;5;241m.\u001B[39mregister(\u001B[38;5;28mid\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShogi-v0\u001B[39m\u001B[38;5;124m\"\u001B[39m, entry_point\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menv:ShogiEnv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\ict\\sem7\\data_challange\\environment\\src\\agent\\shogi_agent.py:13\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mshogi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Move\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01menv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ShogiEnv\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeep_q_network\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DQN\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'env'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.environment.env import ShogiEnv\n",
    "from src.agent.shogi_agent import ShogiAgent\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gym.register(id=\"Shogi-v0\", entry_point=\"env:ShogiEnv\")\n",
    "env: ShogiEnv = gym.make(\"Shogi-v0\")\n",
    "agent = ShogiAgent()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T15:20:10.109682600Z",
     "start_time": "2024-06-01T15:20:05.046408700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def play_game(environment: ShogiEnv, player: ShogiAgent) -> (float, bool, bool):\n",
    "    losses = []\n",
    "    rewards = []\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    environment.reset()\n",
    "    agent.reset()\n",
    "\n",
    "    while not terminated and not truncated:\n",
    "        current_state = env.get_observation()\n",
    "\n",
    "        # Take action\n",
    "        action, mask_index = player.select_action(environment)\n",
    "        state, reward, terminated, truncated, _ = environment.step(action)\n",
    "\n",
    "        # Update the player\n",
    "        player.adaptive_e_greedy()\n",
    "        new_state = env.get_observation()\n",
    "        loss = player.train_model(\n",
    "            mask_index,\n",
    "            reward,\n",
    "            (terminated or truncated),\n",
    "            current_state,\n",
    "            new_state,\n",
    "        )\n",
    "\n",
    "        rewards.append(reward)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return rewards, terminated, truncated, losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T15:20:10.110682Z",
     "start_time": "2024-06-01T15:20:10.109682600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "progress = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-01T15:20:10.111682800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T15:20:10.115868500Z",
     "start_time": "2024-06-01T15:20:10.113682200Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    start = time.time()\n",
    "    reward_list, _terminated, _truncated, loss_list = play_game(env, agent)\n",
    "    end = time.time()\n",
    "    print(f\"{i}: {end - start}\")\n",
    "\n",
    "    progress.append(\n",
    "        {\n",
    "            \"reward\": sum(reward_list),\n",
    "            \"loss\": sum(loss_list),\n",
    "            \"terminated\": _terminated,\n",
    "            \"truncated\": _truncated,\n",
    "            \"duration\": end - start,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(progress)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.plot(df.index, df[\"reward\"], linewidth=0.1)\n",
    "ax1.set_title(\"Total rewards by game\")\n",
    "\n",
    "ax2.plot(df.index, df[\"loss\"], linewidth=0.1)\n",
    "ax2.set_title(\"Total loss by game\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-01T15:20:10.115868500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-01T15:20:10.117878300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.save_model(\"models/test_1.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-01T15:20:10.118878900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
